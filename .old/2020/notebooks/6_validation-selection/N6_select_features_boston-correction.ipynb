{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Feature selection using Subset selection and Lasso\n",
    "\n",
    "Use stepwise procedures or Lasso to select the best\n",
    "features from the Boston dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Load the boston dataset.\n",
    "boston = load_boston()\n",
    "X, y = boston['data'], boston['target']\n",
    "print(boston['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most significant features: ['CHAS' 'RM' 'PTRATIO' 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "# We use Forward stepwise selection, aka Orthogonal Matching Pursuit\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "\n",
    "# Get the three most significant features\n",
    "omp = OrthogonalMatchingPursuit(n_nonzero_coefs=4,fit_intercept=True, normalize=True)\n",
    "omp.fit(X, y)\n",
    "coef = omp.coef_\n",
    "idx_r, = coef.nonzero()\n",
    "\n",
    "sel_feat_name= boston['feature_names'][idx_r] ;\n",
    "print(\"Most significant features: \" + str(sel_feat_name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e664467d676444dbbc34483f2be649b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the selected two first features from X.\n",
    "plt.figure (figsize=(8,4))\n",
    "plt.title(\n",
    "    \"Features selected from Boston using OMP\" )\n",
    "feature1 = X[:, idx_r[1] ]\n",
    "feature2 = X[:, idx_r[2] ]\n",
    "plt.plot(feature1, feature2, 'r.')\n",
    "plt.xlabel(\"Feature number 1\" + sel_feat_name[0])\n",
    "plt.ylabel(\"Feature number 2\" + sel_feat_name[1])\n",
    "plt.ylim([np.min(feature2), np.max(feature2)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features rank: [ 5  7  6  1  1  1 10  2  4  8  1  9  3]\n",
      "Most significant features: ['CHAS' 'NOX' 'RM' 'PTRATIO']\n"
     ]
    }
   ],
   "source": [
    "# We use Backward stepwise selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "estimator = LinearRegression(fit_intercept=True, normalize=True)\n",
    "backsel= RFE(estimator, 4) \n",
    "backsel.fit(X,y)\n",
    "idx_r= backsel.support_ \n",
    "print(\"features rank: \" + str(backsel.ranking_) )\n",
    "sel_feat_name= boston['feature_names'][idx_r] ;\n",
    "print(\"Most significant features: \" + str(sel_feat_name) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso: cross validated penalty parameter -log10(alpha)= 0.13976957498012116\n",
      "Lasso: number of non-zero features: 10\n",
      "Three most significant features: ['RM' 'DIS' 'PTRATIO' 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "# We use the base estimator LassoCV since the L1 norm promotes sparsity of features.\n",
    "clf = LassoCV(cv=5)\n",
    "clf.fit(X, y)\n",
    "idx_r, = clf.coef_.nonzero()\n",
    "print(\"Lasso: cross validated penalty parameter -log10(alpha)= \" + str(-np.log10(clf.alpha_) ) )\n",
    "print(\"Lasso: number of non-zero features: \" + str(idx_r.shape[0]) )\n",
    "\n",
    "\n",
    "# Set a number of features equal to three\n",
    "sfm = SelectFromModel(clf, max_features=4)\n",
    "sfm.fit(X, y)\n",
    "n_features = sfm.transform(X).shape[1]\n",
    "X_transform = sfm.transform(X)\n",
    "\n",
    "sel_feat_name= boston['feature_names'][sfm.get_support()] ;\n",
    "print('Three most significant features: ' + str(sel_feat_name) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing regularization path using the LARS ...\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chatelaf/miniconda3/envs/calc/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in log10\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1842160880744e7082ed76990776e09a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import lars_path\n",
    "\n",
    "print(\"Computing regularization path using the LARS ...\")\n",
    "alphas, actives, coefs = lars_path(X, y, method='lasso', verbose=True)\n",
    "\n",
    "xx = np.sum(np.abs(coefs.T), axis=1)\n",
    "xx /= xx[-1]\n",
    "\n",
    "m_log_alphas = -np.log10(alphas)\n",
    "xx= m_log_alphas.T\n",
    "\n",
    "plt.figure (figsize=(10,5))\n",
    "plt.plot(xx, coefs.T)\n",
    "ymin, ymax = plt.ylim()\n",
    "plt.vlines(xx, ymin, ymax, linestyle='dashed')\n",
    "plt.xlabel('-log10(alpha)')\n",
    "\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('LASSO Path')\n",
    "plt.axis('tight')\n",
    "plt.legend( boston['feature_names'] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice\n",
    "- Do the different selection methods give the same results? How can this be explained?\n",
    "- Apply a Random Forest Regressor (`sklearn.ensemble.RandomForestRegressor`) on this dataset\n",
    "  - What are the most important feature according to this model?\n",
    "  - Apply recursive feature elimination (backward selection) to retain the only 4 most important feature (and compare with linear models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the RFE object and rank each pixel\n",
    "rf = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=5 )\n",
    "\n",
    "RFE_rf = RFE(estimator=rf, n_features_to_select=4, verbose=True)\n",
    "RFE_rf.fit(X, y)\n",
    "ranking_rf = RFE_rf.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  9  7 10  2  1  4  1  8  5  3  6  1]\n",
      "[ True False False False False  True False  True False False False False\n",
      "  True]\n"
     ]
    }
   ],
   "source": [
    "print(ranking_rf)\n",
    "print(RFE_rf.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features rank: [ 1  9  7 10  2  1  4  1  8  5  3  6  1]\n",
      "Most significant features: ['CRIM' 'RM' 'DIS' 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "idx_r= RFE_rf.support_\n",
    "print(\"features rank: \" + str(RFE_rf.ranking_) )\n",
    "sel_feat_name= boston['feature_names'][idx_r] ;\n",
    "print(\"Most significant features: \" + str(sel_feat_name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
